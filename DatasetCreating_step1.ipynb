{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DatasetCreating_step1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PF5ZwnJ4wr0U"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "import imageio\n",
        "import glob\n",
        "from PIL import Image\n",
        "\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "import re\n",
        "import pickle\n",
        "import tqdm\n",
        "import time\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function for cropping imahes and masks\n",
        "\n",
        "def get_patches_custom(img_arr, size=256, stride=256):\n",
        "    \"\"\"\n",
        "    Takes single image or array of images and returns\n",
        "    crops using sliding window method.\n",
        "    If stride < size it will do overlapping.\n",
        "    \"\"\"   \n",
        "     \n",
        "    # check size and stride\n",
        "    if size % stride != 0:\n",
        "        raise ValueError(\"size % stride must be equal 0\")\n",
        "\n",
        "    patches_list = []\n",
        "    overlapping = 0\n",
        "    if stride != size:\n",
        "        overlapping = (size // stride) - 1\n",
        "\n",
        "    if img_arr.ndim == 3:\n",
        "        i_max = img_arr.shape[0] // stride - overlapping\n",
        "        j_max = img_arr.shape[1] // stride - overlapping\n",
        "        for i in range(i_max):\n",
        "            for j in range(j_max):\n",
        "                patches_list.append(\n",
        "                    img_arr[\n",
        "                        i * stride : i * stride + size,\n",
        "                        j * stride : j * stride + size\n",
        "                    ]\n",
        "                )\n",
        "\n",
        "    elif img_arr.ndim == 4:\n",
        "        i_max = img_arr.shape[1] // stride - overlapping\n",
        "        for im in img_arr:\n",
        "            for i in range(i_max):\n",
        "                for j in range(i_max):\n",
        "                    patches_list.append(\n",
        "                        im[\n",
        "                            i * stride : i * stride + size,\n",
        "                            j * stride : j * stride + size,\n",
        "                        ]\n",
        "                    )\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"img_arr.ndim must be equal 3 or 4\")\n",
        "\n",
        "    return np.stack(patches_list)"
      ],
      "metadata": {
        "id": "iq3PKz2ewz4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for 2-class segmentation\n",
        "# this code creates white-black masks\n",
        "\n",
        "#path_mask = \"/Users/anastasia/Desktop/Нейросети/Project/train_val_masks_3cl/\"\n",
        "#filename_mask = [f for f in listdir(path_mask) if isfile(join(path_mask, f)) and re.search('\\d',f)]\n",
        "#filename_mask.sort()\n",
        "\n",
        "#for n in range(0,len(filename_mask)):\n",
        "#    print(n)\n",
        "#    mask = Image.open(path_mask + \"/\" + filename_mask[n])\n",
        "#    for i in range(mask.size[0]):\n",
        "#        for j in range(mask.size[1]):\n",
        "#            a = mask.getpixel((i, j))\n",
        "#            if a == (0, 255, 0) or a == (255, 0, 0):\n",
        "#                mask.putpixel((i, j), (255, 255, 255))\n",
        "#    mask.save(filename_mask[n]) "
      ],
      "metadata": {
        "id": "QDGFoqUXwz69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for dataset\n",
        "\n",
        "def create_dataset(path_img, path_mask, crop_size):\n",
        "\n",
        "    filename_img = [f for f in listdir(path_img) if isfile(join(path_img, f)) and re.search('\\d',f)]\n",
        "    filename_img.sort()\n",
        "    filename_mask = [f for f in listdir(path_mask) if isfile(join(path_mask, f)) and re.search('\\d',f)]\n",
        "    filename_mask.sort()\n",
        "    \n",
        "    w_size = np.arange(0,len(filename_img))\n",
        "    h_size = w_size.copy()\n",
        "    n = 0\n",
        "    x_crops_image = np.zeros((0, crop_size, crop_size, 3))\n",
        "    x_crops_mask = np.zeros((0, crop_size, crop_size, 3))\n",
        "    \n",
        "    for n in range(0,len(filename_img)):\n",
        "        print(filename_img[n])\n",
        "        print(filename_mask[n])\n",
        "        \n",
        "        image = imageio.imread(path_img + \"/\" + filename_img[n])[:,:,0:3]\n",
        "        print(image.shape, 'image')\n",
        "        w_size[n] = image.shape[0]\n",
        "        h_size[n] = image.shape[1]\n",
        "        \n",
        "        if  w_size[n] > h_size[n]:\n",
        "            image = np.swapaxes(image,0,1)\n",
        "            tmp = w_size[n]\n",
        "            w_size[n] = h_size[n]\n",
        "            h_size[n] = tmp\n",
        "            \n",
        "        x_crops = get_patches_custom(\n",
        "            img_arr=image.astype(int), # required - array of images to be cropped\n",
        "            size=crop_size, # default is 256\n",
        "            stride=crop_size) # default is 256\n",
        "        x_crops.astype(np.uint8)\n",
        "        print(x_crops.shape, 'image_cropped')\n",
        "        \n",
        "        del (image)\n",
        "        x_crops_image = np.append(x_crops_image, x_crops, axis=0)\n",
        "        del(x_crops)\n",
        "        \n",
        "        mask = imageio.imread(path_mask + \"/\" + filename_mask[n])[:,:,0:3]\n",
        "        print(mask.shape, 'mask')\n",
        "        x_crops = get_patches_custom(\n",
        "            img_arr=mask.astype(int), # required - array of images to be cropped\n",
        "            size=crop_size, # default is 256\n",
        "            stride=crop_size) # default is 256\n",
        "        x_crops.astype(np.uint8)\n",
        "        \n",
        "        del(mask)\n",
        "        print(x_crops.shape, 'mask_cropped')\n",
        "        x_crops_mask = np.append(x_crops_mask, x_crops, axis=0)\n",
        "        del(x_crops)\n",
        "        \n",
        "    len_dataset = x_crops_image.shape[0]\n",
        "    y_crops = np.zeros((len_dataset, 1))\n",
        "            \n",
        "\n",
        "    x_final = np.squeeze(x_crops_image)\n",
        "    x_final_mask = np.squeeze(x_crops_mask)\n",
        "    \n",
        "    return x_final.astype(np.uint8), x_final_mask.astype(np.uint8)"
      ],
      "metadata": {
        "id": "UG1pcpDCwz9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_img = '/gdrive/My Drive/TyurinaAV_segmentation/DatasetCreating/current_image/'\n",
        "path_mask = '/gdrive/My Drive/TyurinaAV_segmentation/DatasetCreating/current_mask/'\n",
        "\n",
        "crop_size = 256\n",
        "\n",
        "imgs_cropped, masks_cropped = create_dataset(path_img, path_mask, crop_size)"
      ],
      "metadata": {
        "id": "Q5YMbSkAw0AR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_random_Images(images_arr, mask_arr):\n",
        "    fig, axes = plt.subplots(2, 10, figsize=(20,5))\n",
        "    axes = axes.flatten()\n",
        "    rand_num = np.random.randint(0, len(images_arr), size=10)\n",
        "    \n",
        "    print(rand_num)\n",
        "    \n",
        "    for k in range(0,10):\n",
        "        axes[k].imshow(images_arr[rand_num[k]])\n",
        "        axes[k+10].imshow(mask_arr[rand_num[k]])\n",
        "        \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_random_Images(imgs_cropped, masks_cropped)"
      ],
      "metadata": {
        "id": "UTaZmH5qw0CZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_images = torch.from_numpy(imgs_cropped/255)\n",
        "del imgs_cropped\n",
        "print(x_images.shape)\n",
        "x_images = torch.transpose(x_images, 1, 3)\n",
        "x_images = torch.transpose(x_images, 2, 3)\n",
        "print(x_images.shape)\n",
        "y_labels = torch.from_numpy(masks_cropped/255)\n",
        "del masks_cropped\n",
        "print(y_labels.shape)\n",
        "y_labels = y_labels[:,:,:,2].unsqueeze(1)\n",
        "print(y_labels.shape)\n",
        "\n",
        "x_images_new = x_images.numpy()\n",
        "del x_images\n",
        "print(x_images_new.shape)\n",
        "y_labels_new = y_labels.numpy()\n",
        "del y_labels\n",
        "print(y_labels_new.shape)"
      ],
      "metadata": {
        "id": "TOgqEX_pyOdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_images():\n",
        "    for i in range(100000):\n",
        "        yield i\n",
        "i_name_images = gen_images()\n",
        "\n",
        "def gen_masks():\n",
        "    for i in range(100000):\n",
        "        yield i\n",
        "i_name_masks = gen_masks()"
      ],
      "metadata": {
        "id": "3vVs32-qyOjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving train images\n",
        "n = 0\n",
        "for cropping in tqdm(x_images_new):\n",
        "    with open(f'/gdrive/My Drive/TyurinaAV_segmentation/DatasetCreating/datasets/train_val_images/image_{next(i_name_images)+n}', 'wb+') as f:\n",
        "        pickle.dump(cropping, f)"
      ],
      "metadata": {
        "id": "nEj41_ZFyOma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# and masks\n",
        "for cropping in tqdm(y_labels_new):\n",
        "    with open(f'/gdrive/My Drive/TyurinaAV_segmentation/DatasetCreating/datasets/train_val_masks/mask_{next(i_name_masks)+n}', 'wb+') as f:\n",
        "        pickle.dump(cropping, f)"
      ],
      "metadata": {
        "id": "kCfTbdil4dv5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}