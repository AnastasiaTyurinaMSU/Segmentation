{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pjJ-Lke_gMLC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35d6a51a-3375-4730-b375-3c221df8b083"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import glob\n",
        "from PIL import Image\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader,  TensorDataset, Dataset\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "from os import listdir\n",
        "import shutil\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "import imageio\n",
        "import time\n",
        "\n",
        "import pickle\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "import random\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "YG2ToT0YgMLG"
      },
      "outputs": [],
      "source": [
        "# dataset creating \n",
        "class MyDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, data, targets, transform=None):\n",
        "        self.dir_data = data\n",
        "        self.dir_targets = targets\n",
        "\n",
        "        self.list_data = listdir(data)\n",
        "        self.list_targets = listdir(targets)\n",
        "\n",
        "        self.list_data.sort()\n",
        "        self.list_targets.sort()\n",
        " \n",
        "    def __len__(self):\n",
        "        if len(listdir(self.dir_data)) != len(listdir(self.dir_targets)):\n",
        "            raise Exception(f'error {len(listdir(self.dir_data))} {len(listdir(self.dir_targets))}')\n",
        "        return len(listdir(self.dir_data))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        with open(f'{self.dir_data}/{self.list_data[idx]}', 'rb') as f:\n",
        "            image = pickle.load(f)\n",
        "\n",
        "        with open(f'{self.dir_targets}/{self.list_targets[idx]}', 'rb') as f:\n",
        "            label = pickle.load(f)\n",
        "\n",
        "        return torch.from_numpy(image).float(), torch.from_numpy(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "1WH06hsxgMLK"
      },
      "outputs": [],
      "source": [
        "# dataset\n",
        "dir_img = '/gdrive/My Drive/TyurinaAV_segmentation/DatasetCreating/datasets/train_val_images/'\n",
        "dir_mask = '/gdrive/My Drive/TyurinaAV_segmentation/DatasetCreating/datasets/train_val_masks/'\n",
        "\n",
        "dataset = MyDataset(data=dir_img, targets=dir_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fi_zeoZi4AV"
      },
      "outputs": [],
      "source": [
        "# classes balancing\n",
        "# indices of images with total black and wb zones\n",
        "counter_black = []\n",
        "counter_wb = []\n",
        "for i in tqdm(range(len(dataset))):\n",
        "    if i%50 == 0:\n",
        "        time.sleep(10)\n",
        "    if dataset[i][1].max() > 0:\n",
        "        counter_wb.append(i)\n",
        "        #print(i,'wb')\n",
        "    else:\n",
        "        counter_black.append(i)\n",
        "        #print(i,'b')\n",
        "\n",
        "print(len(counter_black))\n",
        "print(len(counter_wb))\n",
        "#print(len(set(counter_wb))+len(set(counter_black)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6kS57o9r34g"
      },
      "outputs": [],
      "source": [
        "# chosing random images of the same amount\n",
        "ind_black = random.sample(counter_black, 2600)\n",
        "ind_wb = random.sample(counter_wb, 2600)\n",
        "#len(set(ind_black))+len(set(ind_wb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lVKqcsEOufP"
      },
      "outputs": [],
      "source": [
        "ind = ind_black + ind_wb\n",
        "print(len(set(ind)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "974DlgYQ86WX"
      },
      "outputs": [],
      "source": [
        "# copying files from full dataset to creat balanced dataset\n",
        "for index in tqdm((ind)):\n",
        "    #if i%100 == 0:\n",
        "    #    time.sleep(10)\n",
        "    shutil.copy(f'/gdrive/My Drive/TyurinaAV_segmentation/DatasetCreating/datasets/train_val_images/image_{index}', f'/gdrive/My Drive/TyurinaAV_segmentation/DatasetCreating/datasets/train_val_images_balanced/image_{index}')\n",
        "    shutil.copy(f'/gdrive/My Drive/TyurinaAV_segmentation/DatasetCreating/datasets/train_val_masks/mask_{index}', f'/gdrive/My Drive/TyurinaAV_segmentation/DatasetCreating/datasets/train_val_masks_balanced/mask_{index}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "DatasetCreating_step2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}